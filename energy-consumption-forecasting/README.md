# Household energy consumption forecasting



## Time Series Forecasting
The task is to predict the future data points, given some historical data.\
The examples include weather forecasting, retail and sales forecasting, stock market prediction, and behavior prediction.\
In this project, the household energy consumption data originally taken from Kaggle was used (https://www.kaggle.com/datasets/uciml/electric-power-consumption-data-set).

## Overview of the Notebook
- Load in and explore household energy consumption data
- Clean the data and transform it to prepare for training a model
- Format the data into JSON Lines
- Train a DeepAR model on defined context and prediction data points
- Evaluate the model by comparing known and predicted consumption values

## DeepAR Model
DeepAR utilizes a recurrent neural network (RNN) to take many target time series that have been generated by same or similar processes as training inputs, 
learn to approximate the generation process by taking random samples from them, and predict how the target time series would evolve (https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html). 

### Inputs
DeepAR expects to see input training data in a JSON format, with the following fields:
- start: A string that defines the starting date of the time series, with the format 'YYYY-MM-DD HH:MM:SS'.
- target: An array of numerical values that represent the time series.
- cat (optional): A numerical array of categorical features that can be used to encode the groups that the record belongs to. This is useful for finding models per class of item, such as in retail sales, where you might have {'shoes', 'jackets', 'pants'} encoded as categories {0, 1, 2}.

The input data should be formatted with one time series per line in a JSON file. Each line looks a bit like a dictionary, for example:

> {"start":'2007-01-01 00:00:00', "target": [2.54, 6.3, ...], "cat": [1]} \
  {"start": "2012-01-30 00:00:00", "target": [1.0, -5.0, ...], "cat": [0]} 

### Training
SageMaker trains the DeepAR model by randomly sampling training examples from each target time series in the training dataset.\
Each training example consists of a pair of adjacent context and prediction windows with fixed predefined lengths, which control how far in the past the model can ses and 
how far in the future predictions can be made, respectively. 

Essential hyperparameters for the estimator include:
- epochs: The maximum number of times to pass over the data when training.
- time_freq: The granularity of the time series in the dataset ('D' for daily).
- prediction_length: A string; the number of time steps (based off the unit of frequency) that the model is trained to predict.
- context_length: The number of time points that the model gets to see before making a prediction.

![image](https://user-images.githubusercontent.com/39967211/233966756-f42d8778-7b55-4436-a47e-b245ea0b2a83.png)

### Outputs
The predictor returns JSON-formatted prediction, so the predictions and quantile data need to be extracted for visualization. 




